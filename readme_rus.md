## Задачи, выполненные в рамках курса Deep Learning от [DLS(МФТИ)](https://www.dlschool.org/)
### Основной фрэймворк: PyTorch

1. [Классификация персонажей мультсериала "Симпсоны" (kaggle competition)](Classification_of_Simpsons_series_characters.ipynb)
   * Transfer learning
   * Аугментации
   * Взвешенное сэмплирование
   * Ансамбль из трёх моделей
   * кастомный класс датасета с раширенными возможностями
   * обёртка для базового Subset, с возможностью применять к каждому сабсету свой стэк аугментаций.
   
2. [Сегментация медицинских изображений](Segmentation_of_dermatoscopic_images.ipynb)
   * Кастомные классы Dataset и Subset с дополнительным функционалом.
   * Аугментации на базе Albumentations
   * Два варианта SegNet (единым классом и модульный, где каждый блок реализован отдельным классом)
   * Два варианта U-Net (с MaxPooling и Upsampling, и на обычных и траспонированных свёртках с шагом 2)
   * Функция обучения и валидации с дополнительным функционалом (визуализация, sheduler и т.д.)
   * Пишем IoU с нуля в качестве метрики
   * Пишем простые лосс функции с нуля: BCE loss, DICE loss, Focal loss
   * Пишем кастомные сегментационные лоссы на базе статей с arxiv.org:<br> TotalVariation loss, Tversky loss, Lovasz-Hinge loss, Sctructural Similarity Loss (SSL)
   * Сравнение всех моделей и лоссов и общие выводы по всему эксперименту.
   
4. [Автокодировщики](Autoencoders.ipynb)
   * Функция сборки и предобработки данных. (скачивание, трансформы, сортировка, дополнительные атрибуты)
   * Реализация классического автокодировщика Vanilla Autoencoder в двух вариантах (линейные слои, свёртки)
   * Функция обучения и валидации с дополнительным функционалом (визуализация, sheduler и т.д.)
   * Генерация случайных изображений
   * Векторная арифметика в латентном пространстве. "Заставляем людей на фото улыбаться"
   * Реализация вариационного автокодировцика (Variational Autoencoder) в двух вариантах (линейные слои, свёртки)
   * Пишем композитный лосс для VAE (KL-дивергенция + log-likelihood)
   * Генерация случайных цифр (VAE обучаем на MNIST-датасете)
   * Реализация условного вариационного автокодировщика (Conditional VAE)
   * Генерация цифр с выбором класса(цифры) (CVAE обучаем на MNIST-датасете)
   * Сравнение распределений в латентном пространстве (понижаем t-SNE размерность до 2).
   * Реализуем Denoiser на базе VAE.
   * Реализуем распознавание лиц на базе VAE (ищем ближайшие в латентном пространстве используя косинусное сходство)
   
6. [Генеративные состязательные сети](GANs.ipynb)
   * Кастомный класс Dataset с дополнительным функционалом (зашиваем аугментации в класс)
   * Враппер для обычного Dataloader с возвращением батча сразу на нужный device
   * Реализация архитектуры DCGAN
   * GAN-hacks (добавляем label smoothing и гауссов шум для улучшения стабильности обучения)
   * Функция обучения с дополнительными возможностями (scheduler-ы, коэффициент сглаживания и т.д.)
   * Генерация лиц
   * Оцениваем качество сгенерированных изображений по Leave One Out 1NN Classifier accuracy
   * Сравнение распределений фейковых и реальных изображений (размерность понижаем TSNE)
